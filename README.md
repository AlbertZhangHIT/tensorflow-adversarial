Adversarial Attack with Tensorflow
==================================

## API ##

Four
[adversarial image](http://karpathy.github.io/2015/03/30/breaking-convnets/) crafting
algorithms are implemented with Tensorflow.  The four attacking
algorithms can be found in [**attacks**](./attacks) folder.  They all
return a Tensorflow operation which could be run through
`sess.run(...)`.

- Fast Gradient Sign Method
  (FGSM)
  [basic](https://arxiv.org/abs/1412.6572)/[iterative](https://arxiv.org/abs/1607.02533)

    ```python
fgsm(model, x, eps=0.01, nb_epoch=1, clip_min=0.0, clip_max=1.0)
    ```

- [Target class Gradient Sign Method (TGSM)](https://arxiv.org/abs/1607.02533)

    ```python
tgsm(model, x, y=None, eps=0.01, nb_epoch=1, clip_min=0.0, clip_max=1.0)
    ```

    When `y=None`, this implements the least-likely class method.  If
    `y` is an integer or a list of integers, the source image is
    modified towards label `y`.

- [Jacobian-based Saliency Map Approach (JSMA)](https://arxiv.org/abs/1511.07528)

    ```python
jsma(model, x, y, nb_epoch=None, tol=1.0, eps=1., clip_min=0.0, clip_max=1.0, pair=False, min_proba=0.0)
    ```

    `y` is the target label, could be an integer or a list.  `tol`
    ranges [0,1], denoting the maximum distortion to the image.
    `min_proba` denotes the minimum confidence of target image.  If
    `pair=True`, then modifies two pixels at a time.

- Saliency map difference approach (SMDA)

    ```python
smda(model, x, target, nb_epoch=None, delta=1., clip_min=0., clip_max=1.)
    ```

## Fun Examples ##

- [**ex_00.py**](./ex_00.py) trains a simple CNN on MNIST, achieving
  accuracy ~99%.  Then craft with FGSM adversarial samples from test
  data, of which the CNN accuracy drops to 0% depending on your choice
  of `eps` and `nb_epoch`.  The original label for the following
  digits are 0 through 9 originally, and the predicted label with
  probability are shown below each digit.

    ![ex_00](./img/ex_00.png?raw=true "fgsm digits")

- [**ex_01.py**](./ex_01.py) creates cross label adversarial images
  via saliency map algorithm (JSMA), left image.  For each row, the
  digit in green frame is the natural one based on which others are
  created.

    <img src="./img/ex_01.png" width="45%">
    <img src="./img/ex_02.png" width="45%">

- [**ex_02.py**](./ex_02.py) creates cross label adversarial images
  via paired saliency map algorithm (JSMA2), right image.

- [**ex_03.py**](./ex_03.py) creates digits from blank images via
  saliency different algorithm (SMDA).

    ![ex_03](./img/ex_03.png?raw=true "digits from scratch")

- [**ex_04.py**](./ex_04.py) creates digits from blank images via
  paired saliency map algorithm (JSMA2).

    ![ex_04](./img/ex_04.png?raw=true "digits from scratch")

- [**ex_05.py**](./ex_05.py) trains a simple CNN on MNIST, achieving
  accuracy ~99%.  Then craft with LLCM adversarial samples from test
  data, of which the CNN accuracy drops to ~1% depending on your
  choice of `eps` and `nb_epoch`.  The original label for the
  following digits are 0 through 9 originally, and the predicted label
  with probability are shown below each digit.

    ![ex_05](./img/ex_05.png?raw=true "llcm digits")

- [**ex_06.py**](./ex_06.py) trains a CNN on CIFAR10, achieving
  accuracy ~85.02%.  FGSM reduces the accuracy to ~0.22%.  The
  followings are some adversarial samples generated by FGSM.

    ![ex_06](./img/ex_06.png?raw=true "fgsm cifar10")

## Related Work ##

- [openai/cleverhans](https://github.com/openai/cleverhans)
